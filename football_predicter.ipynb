{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afd3bf03",
   "metadata": {},
   "source": [
    "# Premier League Predictor v4.0 (Class Balancing & Model Saving)\n",
    "\n",
    "### Novidades:\n",
    "1.  **For√ßar Empates:** Vamos aplicar pesos √†s classes (`sample_weights`) para o modelo deixar de ignorar os empates.\n",
    "2.  **Instant Load:** O modelo treinado √© guardado no disco. Na pr√≥xima execu√ß√£o, n√£o precisas de treinar de novo.\n",
    "3.  **Thresholds Din√¢micos:** Em vez de escolher apenas a maior probabilidade, vamos ver se a probabilidade de empate √© \"decente\" (ex: > 28%) e arriscar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62edbbd4",
   "metadata": {},
   "source": [
    "Imports e Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950eca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib # Para salvar o modelo\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14553427",
   "metadata": {},
   "source": [
    "## 1. Data Acquisition (Recolha de Dados)\n",
    "Vamos buscar dados reais do `football-data.co.uk`. Vamos carregar v√°rias temporadas consecutivas para que o modelo tenha hist√≥rico suficiente para aprender padr√µes.\n",
    "\n",
    "* **FTHG**: Full Time Home Goals\n",
    "* **FTAG**: Full Time Away Goals\n",
    "* **FTR**: Full Time Result (H=Home, D=Draw, A=Away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27652b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'premier_league_v3_full.csv'\n",
    "\n",
    "def get_data(start_year, end_year):\n",
    "    # 1. Verificar se ficheiro existe localmente\n",
    "    if os.path.exists(DATA_FILE):\n",
    "        print(f\"Ficheiro local '{DATA_FILE}' encontrado! A carregar...\")\n",
    "        df = pd.read_csv(DATA_FILE)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        # Se quiseres atualizar dados recentes, apaga o ficheiro .csv da pasta e corre isto de novo\n",
    "        return df\n",
    "    \n",
    "    # 2. Se n√£o existe, sacar da net\n",
    "    print(\"Ficheiro n√£o encontrado. A fazer download da internet...\")\n",
    "    base_url = \"https://www.football-data.co.uk/mmz4281/{}/{}.csv\"\n",
    "    dfs = []\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        season_str = f\"{str(year)[-2:]}{str(year+1)[-2:]}\"\n",
    "        url = base_url.format(season_str, \"E0\")\n",
    "        try:\n",
    "            df = pd.read_csv(url)\n",
    "            df['Season'] = year\n",
    "            # Normalizar Data\n",
    "            df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro no ano {year}: {e}\")\n",
    "            \n",
    "    full_df = pd.concat(dfs, ignore_index=True)\n",
    "    full_df = full_df.dropna(subset=['Date', 'FTR'])\n",
    "    full_df = full_df.sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # Guardar para a pr√≥xima vez\n",
    "    full_df.to_csv(DATA_FILE, index=False)\n",
    "    print(\"‚úÖ Download conclu√≠do e guardado no PC.\")\n",
    "    return full_df\n",
    "\n",
    "# Carregar dados\n",
    "df = get_data(2005, 2025)\n",
    "display(df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a02a0a",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Completa (ELO + Stats + Odds)\n",
    "\n",
    "Aqui adicionamos as colunas B365H, B365D, B365A (Odds da Bet365)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f923a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df, window=5):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # --- 1. ELO SYSTEM ---\n",
    "    elo_dict = {}\n",
    "    df['HomeElo'] = 1500.0\n",
    "    df['AwayElo'] = 1500.0\n",
    "    k_factor = 20\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        h, a, res = row['HomeTeam'], row['AwayTeam'], row['FTR']\n",
    "        h_elo = elo_dict.get(h, 1500.0)\n",
    "        a_elo = elo_dict.get(a, 1500.0)\n",
    "        \n",
    "        df.at[i, 'HomeElo'] = h_elo\n",
    "        df.at[i, 'AwayElo'] = a_elo\n",
    "        \n",
    "        if res == 'H': val = 1\n",
    "        elif res == 'D': val = 0.5\n",
    "        else: val = 0\n",
    "        \n",
    "        exp_h = 1 / (1 + 10**((a_elo - h_elo)/400))\n",
    "        new_h = h_elo + k_factor * (val - exp_h)\n",
    "        new_a = a_elo + k_factor * ((1-val) - (1-exp_h))\n",
    "        \n",
    "        elo_dict[h] = new_h\n",
    "        elo_dict[a] = new_a\n",
    "        \n",
    "    df['EloDiff'] = df['HomeElo'] - df['AwayElo']\n",
    "    \n",
    "    # --- 2. ROLLING STATS ---\n",
    "    home_stats = df[['Date', 'HomeTeam', 'FTHG', 'FTAG', 'HS', 'HST', 'HC']].copy()\n",
    "    home_stats.columns = ['Date', 'Team', 'Goals', 'Conceded', 'Shots', 'SoT', 'Corners']\n",
    "    home_stats['Points'] = df['FTR'].map({'H':3, 'D':1, 'A':0})\n",
    "    \n",
    "    away_stats = df[['Date', 'AwayTeam', 'FTAG', 'FTHG', 'AS', 'AST', 'AC']].copy()\n",
    "    away_stats.columns = ['Date', 'Team', 'Goals', 'Conceded', 'Shots', 'SoT', 'Corners']\n",
    "    away_stats['Points'] = df['FTR'].map({'A':3, 'D':1, 'H':0})\n",
    "    \n",
    "    all_stats = pd.concat([home_stats, away_stats]).sort_values(['Team', 'Date'])\n",
    "    \n",
    "    metrics = ['Points', 'Goals', 'Conceded', 'Shots', 'SoT', 'Corners']\n",
    "    for m in metrics:\n",
    "        all_stats[f'Avg_{m}'] = all_stats.groupby('Team')[m].transform(\n",
    "            lambda x: x.shift(1).rolling(window, min_periods=3).mean()\n",
    "        )\n",
    "    \n",
    "    # Merge Home rolling\n",
    "    df = df.merge(\n",
    "        all_stats[['Date', 'Team'] + [f'Avg_{m}' for m in metrics]],\n",
    "        left_on=['Date', 'HomeTeam'],\n",
    "        right_on=['Date', 'Team'],\n",
    "        how='left'\n",
    "    ).drop(columns=['Team'])\n",
    "    df = df.rename(columns={f'Avg_{m}': f'Home_{m}' for m in metrics})\n",
    "    \n",
    "    # Merge Away rolling\n",
    "    df = df.merge(\n",
    "        all_stats[['Date', 'Team'] + [f'Avg_{m}' for m in metrics]],\n",
    "        left_on=['Date', 'AwayTeam'],\n",
    "        right_on=['Date', 'Team'],\n",
    "        how='left'\n",
    "    ).drop(columns=['Team'])\n",
    "    df = df.rename(columns={f'Avg_{m}': f'Away_{m}' for m in metrics})\n",
    "    \n",
    "    # --- 3. BETTING ODDS ---\n",
    "    if 'B365H' in df.columns:\n",
    "        df['Prob_Home'] = 1 / df['B365H']\n",
    "        df['Prob_Draw'] = 1 / df['B365D']\n",
    "        df['Prob_Away'] = 1 / df['B365A']\n",
    "        df = df.dropna(subset=['Prob_Home'])\n",
    "    \n",
    "    # Preencher s√≥ as rolling averages\n",
    "    rolling_cols = [f for f in df.columns if f.startswith(\"Home_\") or f.startswith(\"Away_\")]\n",
    "    df[rolling_cols] = df[rolling_cols].fillna(0)\n",
    "    \n",
    "    # Remover colunas totalmente vazias\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    return df, elo_dict\n",
    "\n",
    "# Aplicar e verificar colunas\n",
    "df_processed, elo_tracker = prepare_features(df)\n",
    "print(\"Colunas dispon√≠veis para treino:\", df_processed.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5a89c",
   "metadata": {},
   "source": [
    "## 3. Prepara√ß√£o e Treino do Modelo\n",
    "Treino Intensivo: Grid Search (Hyperparameter Tuning) Aqui √© onde \"apertamos\" o modelo. Vamos testar v√°rias combina√ß√µes. Nota: Isto pode demorar 2 ou 3 minutos a correr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e9837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preparar Features\n",
    "features = ['HomeElo', 'AwayElo', 'EloDiff', \n",
    "            'Prob_Home', 'Prob_Draw', 'Prob_Away'] + \\\n",
    "           [c for c in df_processed.columns if 'Home_' in c or 'Away_' in c]\n",
    "features = [f for f in features if f in df_processed.columns]\n",
    "\n",
    "# Target\n",
    "le = LabelEncoder()\n",
    "df_processed['Target'] = le.fit_transform(df_processed['FTR'])\n",
    "# 0=Away, 1=Draw, 2=Home (Verifica sempre com le.classes_)\n",
    "\n",
    "# Split Temporal\n",
    "split = int(len(df_processed) * 0.90)\n",
    "train = df_processed.iloc[:split]\n",
    "test = df_processed.iloc[split:]\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train['Target']\n",
    "X_test = test[features]\n",
    "y_test = test['Target']\n",
    "\n",
    "# --- A MUDAN√áA CRUCIAL: Sample Weights ---\n",
    "# Vamos calcular pesos para equilibrar. \n",
    "# Se houver poucos empates, eles ganham um peso gigante.\n",
    "sample_weights = compute_sample_weight(\n",
    "    class_weight='balanced',\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "print(\"‚öñÔ∏è A treinar com pesos equilibrados (Obrigando a olhar para o Empate)...\")\n",
    "\n",
    "# Modelo (Usamos os melhores params que descobriste ou um set robusto)\n",
    "model_v4 = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    objective='multi:softprob'\n",
    ")\n",
    "\n",
    "# Passamos os pesos no .fit()\n",
    "model_v4.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "print(\"‚úÖ Modelo treinado.\")\n",
    "\n",
    "# --- GUARDAR O MODELO (O teu pedido) ---\n",
    "joblib.dump(model_v4, 'model_xgboost_v4.pkl')\n",
    "joblib.dump(le, 'label_encoder.pkl') # Importante guardar o descodificador\n",
    "print(\"üíæ Modelo salvo como 'model_xgboost_v4.pkl'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da910c6c",
   "metadata": {},
   "source": [
    "### Matriz de Confus√£o e accuracy\n",
    "Vamos ver visualmente onde o modelo erra.\n",
    "* Eixo Y: O que realmente aconteceu.\n",
    "* Eixo X: O que o modelo previu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_v4.predict(X_test)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "print(f\"üéØ Accuracy V4: {acc:.2%}\")\n",
    "\n",
    "# Matriz de Confus√£o\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Matriz de Confus√£o (Com Pesos)')\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Real')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report (Para ver a precis√£o espec√≠fica dos Empates/Draws)\n",
    "print(classification_report(y_test, preds, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7176fed1",
   "metadata": {},
   "source": [
    "## 4. Aplica√ß√£o na \"Vida Real\"\n",
    "Aqui est√° a fun√ß√£o final. Ela usa o dicion√°rio `current_elo` (que cont√©m os valores mais recentes ap√≥s o √∫ltimo jogo do dataset) para fazer previs√µes sobre jogos futuros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c1481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_smart(home, away, odd_h, odd_d, odd_a):\n",
    "    # Carregar modelo se n√£o estiver em mem√≥ria\n",
    "    if 'model_v4' not in locals():\n",
    "        model_v4 = joblib.load('model_xgboost_v4.pkl')\n",
    "        print(\"üìÇ Modelo carregado do disco.\")\n",
    "\n",
    "    # 1. Buscar dados (Igual ao v3)\n",
    "    # (Simplifica√ß√£o: assume que elo_tracker e df_processed est√£o em mem√≥ria)\n",
    "    h_elo = elo_tracker.get(home, 1500)\n",
    "    a_elo = elo_tracker.get(away, 1500)\n",
    "    \n",
    "    input_data = {\n",
    "        'HomeElo': h_elo, 'AwayElo': a_elo, 'EloDiff': h_elo - a_elo,\n",
    "        'Prob_Home': 1/odd_h, 'Prob_Draw': 1/odd_d, 'Prob_Away': 1/odd_a\n",
    "    }\n",
    "    \n",
    "    # Preencher stats hist√≥ricas\n",
    "    h_row = df_processed[df_processed['HomeTeam'] == home].iloc[-1]\n",
    "    a_row = df_processed[df_processed['AwayTeam'] == away].iloc[-1]\n",
    "    \n",
    "    for feat in features:\n",
    "        if feat not in input_data:\n",
    "            if 'Home_' in feat: input_data[feat] = h_row[feat]\n",
    "            elif 'Away_' in feat: input_data[feat] = a_row[feat]\n",
    "\n",
    "    X_input = pd.DataFrame([input_data])[features]\n",
    "    \n",
    "    # 2. Obter Probabilidades Reais\n",
    "    probs = model_v4.predict_proba(X_input)[0]\n",
    "    p_away, p_draw, p_home = probs[0], probs[1], probs[2]\n",
    "    \n",
    "    print(f\"\\nüß† An√°lise: {home} vs {away}\")\n",
    "    print(f\"   Probabilidades: Casa {p_home:.0%} | Empate {p_draw:.0%} | Fora {p_away:.0%}\")\n",
    "    \n",
    "    # 3. L√≥gica de Decis√£o Personalizada (Custom Threshold)\n",
    "    # Se o Empate for > 30%, vamos considerar muito prov√°vel, mesmo que n√£o seja o maior\n",
    "    # Ajusta este valor (0.30) conforme o teu gosto de risco\n",
    "    \n",
    "    prediction = \"Inconclusivo\"\n",
    "    \n",
    "    if p_home > 0.45:\n",
    "        prediction = f\"Vit√≥ria {home}\"\n",
    "    elif p_away > 0.45:\n",
    "        prediction = f\"Vit√≥ria {away}\"\n",
    "    elif p_draw > 0.28: # Threshold agressivo para empates\n",
    "        prediction = \"EMPATE (Risco calculado)\"\n",
    "    else:\n",
    "        # Se tudo for baixo (ex: 34, 33, 33), vai pela maior\n",
    "        max_idx = np.argmax(probs)\n",
    "        prediction = f\"Tend√™ncia para {le.classes_[max_idx]}\"\n",
    "\n",
    "    print(f\"   >> Veredicto IA: {prediction}\")\n",
    "\n",
    "# Testa com jogos dif√≠ceis (Derbies costumam dar empate)\n",
    "predict_smart('Aston Villa', 'Arsenal', 4.05, 3.45, 1.84)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
